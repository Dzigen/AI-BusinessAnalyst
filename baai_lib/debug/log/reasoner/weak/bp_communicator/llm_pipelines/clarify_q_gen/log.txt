[2025-08-10 06:47:08.329379] Поиск результата в кеше...
[2025-08-10 06:47:08.329953] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-10 06:47:08.330093] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:47:08.330194] * CACHE_HASH_KEY: 6b934f103157561beb04b2cd2cca6c17f9925876.
[2025-08-10 06:47:08.330418] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать чат-бота и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта. Решение должно работать на основе GigaChat и собственной low-code платформы партнёра. Цель – автоматизация процесса уточнения требований, сокращение недопонимания между заказчиком и разработчиком, улучшение качества подготовки ТЗ.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: Работающий прототип чат-бота и веб-сервиса с функциями:  1. Ведение диалога → уточнение требований → формирование ТЗ. 2. Возможность редактирования ТЗ в диалоге и в облачном документе. 3. Экспорт ТЗ (PDF, DOCX).\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Чат-бот и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта.\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Заказчики цифровых продуктов, которым нужно специфицировать свою задачу для разработчиков\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: 1. GigaChat API. 2.Веб-интерфейс для работы на ПК и мобильных устройствах. 3. Интеграция с облачными документами (через API)\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет. Необходимо изучить литературу для выработки методологии по уточнению технического задания с целью её дальнейшей интеграции в разрабатываемый программный продукт\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с внешними системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Нет', ''].
[2025-08-10 06:47:08.330541] Получаем результат с нуля...
[2025-08-10 06:47:08.956890] Кешируем полученный результат.
[2025-08-10 06:47:08.956988] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:47:08.957071] * CACHE_HASH_KEY: 6b934f103157561beb04b2cd2cca6c17f9925876.
[2025-08-10 06:47:32.822929] Поиск результата в кеше...
[2025-08-10 06:47:32.823276] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-10 06:47:32.823430] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:47:32.823530] * CACHE_HASH_KEY: 99aef0b1f5e2327726ac39a41225a0217a3f93b3.
[2025-08-10 06:47:32.823760] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать чат-бота и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта. Решение должно работать на основе GigaChat и собственной low-code платформы партнёра. Цель – автоматизация процесса уточнения требований, сокращение недопонимания между заказчиком и разработчиком, улучшение качества подготовки ТЗ.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: Работающий прототип чат-бота и веб-сервиса с функциями:  1. Ведение диалога → уточнение требований → формирование ТЗ. 2. Возможность редактирования ТЗ в диалоге и в облачном документе. 3. Экспорт ТЗ (PDF, DOCX).\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Чат-бот и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта.\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Заказчики цифровых продуктов, которым нужно специфицировать свою задачу для разработчиков\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: 1. GigaChat API. 2.Веб-интерфейс для работы на ПК и мобильных устройствах. 3. Интеграция с облачными документами (через API)\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет. Необходимо изучить литературу для выработки методологии по уточнению технического задания с целью её дальнейшей интеграции в разрабатываемый программный продукт\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с внешними системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Нет', 'ba: Какие критерии будут использоваться для оценки корректности сформированного технического задания (ТЗ)?\nuser: С нашей стороны критериев нет: ожидаем предложения/рекомендации с ващей стороны.'].
[2025-08-10 06:47:32.823879] Получаем результат с нуля...
[2025-08-10 06:47:33.605462] Кешируем полученный результат.
[2025-08-10 06:47:33.605557] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:47:33.605665] * CACHE_HASH_KEY: 99aef0b1f5e2327726ac39a41225a0217a3f93b3.
[2025-08-10 06:48:07.176638] Поиск результата в кеше...
[2025-08-10 06:48:07.176963] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-10 06:48:07.177109] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:48:07.177204] * CACHE_HASH_KEY: d98d3126338d276d3e926c8acaab777c164078af.
[2025-08-10 06:48:07.177441] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать чат-бота и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта. Решение должно работать на основе GigaChat и собственной low-code платформы партнёра. Цель – автоматизация процесса уточнения требований, сокращение недопонимания между заказчиком и разработчиком, улучшение качества подготовки ТЗ.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: Работающий прототип чат-бота и веб-сервиса с функциями:  1. Ведение диалога → уточнение требований → формирование ТЗ. 2. Возможность редактирования ТЗ в диалоге и в облачном документе. 3. Экспорт ТЗ (PDF, DOCX).\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Чат-бот и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта.\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Заказчики цифровых продуктов, которым нужно специфицировать свою задачу для разработчиков\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: 1. GigaChat API. 2.Веб-интерфейс для работы на ПК и мобильных устройствах. 3. Интеграция с облачными документами (через API)\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет. Необходимо изучить литературу для выработки методологии по уточнению технического задания с целью её дальнейшей интеграции в разрабатываемый программный продукт\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с внешними системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Нет', 'ba: Какие критерии будут использоваться для оценки корректности сформированного технического задания (ТЗ)?\nuser: С нашей стороны критериев нет: ожидаем предложения/рекомендации с ващей стороны.\nba: Какие типы проектов предполагается охватывать вашим решением — это могут быть исключительно IT-проекты, либо также проекты из других областей деятельности (например, строительство, маркетинг)?\nuser: Разработка веб и мобильных приложений'].
[2025-08-10 06:48:07.177577] Получаем результат с нуля...
[2025-08-10 06:48:07.882540] Кешируем полученный результат.
[2025-08-10 06:48:07.882629] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 06:48:07.882713] * CACHE_HASH_KEY: d98d3126338d276d3e926c8acaab777c164078af.
[2025-08-10 15:13:25.278467] Поиск результата в кеше...
[2025-08-10 15:13:25.288721] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-10 15:13:25.289043] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 15:13:25.289167] * CACHE_HASH_KEY: b9d692d2f1272ec20ffcadeba9de23206ecda2c7.
[2025-08-10 15:13:25.289386] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать чат-бота и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта. Решение должно работать на основе GigaChat и собственной low-code платформы партнёра. Цель – автоматизация процесса уточнения требований, сокращение недопонимания между заказчиком и разработчиком, улучшение качества подготовки ТЗ.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: Работающий прототип чат-бота и веб-сервиса с функциями:  1. Ведение диалога → уточнение требований → формирование ТЗ. 2. Возможность редактирования ТЗ в диалоге и в облачном документе. 3. Экспорт ТЗ (PDF, DOCX).\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Чат-бот и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта.\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Заказчики цифровых продуктов, которым нужно специфицировать свою задачу для разработчиков.\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: 1. GigaChat API. 2.Веб-интерфейс для работы на ПК и мобильных устройствах. 3. Интеграция с облачными документами (через API)\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет. Необходимо изучить литературу для выработки методологии по уточнению технического задания с целью её дальнейшей интеграции в разрабатываемый программный продукт\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с внешними системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Нет', ''].
[2025-08-10 15:13:25.289510] Получаем результат с нуля...
[2025-08-10 15:13:25.909848] Кешируем полученный результат.
[2025-08-10 15:13:25.909966] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 15:13:25.910057] * CACHE_HASH_KEY: b9d692d2f1272ec20ffcadeba9de23206ecda2c7.
[2025-08-10 15:13:30.768339] Поиск результата в кеше...
[2025-08-10 15:13:30.768694] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-10 15:13:30.768822] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 15:13:30.768921] * CACHE_HASH_KEY: 3339d42fb88d6fda15684283e222c2c9038895bb.
[2025-08-10 15:13:30.769149] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать чат-бота и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта. Решение должно работать на основе GigaChat и собственной low-code платформы партнёра. Цель – автоматизация процесса уточнения требований, сокращение недопонимания между заказчиком и разработчиком, улучшение качества подготовки ТЗ.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: Работающий прототип чат-бота и веб-сервиса с функциями:  1. Ведение диалога → уточнение требований → формирование ТЗ. 2. Возможность редактирования ТЗ в диалоге и в облачном документе. 3. Экспорт ТЗ (PDF, DOCX).\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Чат-бот и веб-сервис, которые помогут заказчику формулировать корректное техническое задание (ТЗ) для создания цифрового продукта.\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Заказчики цифровых продуктов, которым нужно специфицировать свою задачу для разработчиков.\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: 1. GigaChat API. 2.Веб-интерфейс для работы на ПК и мобильных устройствах. 3. Интеграция с облачными документами (через API)\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет. Необходимо изучить литературу для выработки методологии по уточнению технического задания с целью её дальнейшей интеграции в разрабатываемый программный продукт\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с внешними системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Нет', 'ba: Какие критерии будут использоваться для оценки корректности сформированного технического задания (ТЗ)?\nuser: С нашей стороны критериев нет: ожидаем предложения/рекомендации с ващей стороны.'].
[2025-08-10 15:13:30.769296] Получаем результат с нуля...
[2025-08-10 15:13:31.573550] Кешируем полученный результат.
[2025-08-10 15:13:31.573652] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-10 15:13:31.573741] * CACHE_HASH_KEY: 3339d42fb88d6fda15684283e222c2c9038895bb.
[2025-08-11 13:29:53.335475] Поиск результата в кеше...
[2025-08-11 13:29:53.335958] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:29:53.336091] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:29:53.336197] * CACHE_HASH_KEY: 1bc09943cf7b1436fb946bd8f6f77f8fe71359c4.
[2025-08-11 13:29:53.336722] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', ''].
[2025-08-11 13:29:53.337012] Получаем результат с нуля...
[2025-08-11 13:29:54.323481] Кешируем полученный результат.
[2025-08-11 13:29:54.323606] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:29:54.323704] * CACHE_HASH_KEY: 1bc09943cf7b1436fb946bd8f6f77f8fe71359c4.
[2025-08-11 13:30:38.813744] Поиск результата в кеше...
[2025-08-11 13:30:38.814213] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:30:38.814349] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:30:38.814457] * CACHE_HASH_KEY: a033c6bc6eb90c2e8e9f7d0bce5fd66c548fb57d.
[2025-08-11 13:30:38.814996] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score'].
[2025-08-11 13:30:38.815263] Получаем результат с нуля...
[2025-08-11 13:30:41.698256] Кешируем полученный результат.
[2025-08-11 13:30:41.698364] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:30:41.698461] * CACHE_HASH_KEY: a033c6bc6eb90c2e8e9f7d0bce5fd66c548fb57d.
[2025-08-11 13:32:16.296883] Поиск результата в кеше...
[2025-08-11 13:32:16.297336] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:32:16.297474] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:32:16.297583] * CACHE_HASH_KEY: 75e66cdbe43bbe6fd18c5560f77da3f5c82a3269.
[2025-08-11 13:32:16.298178] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста'].
[2025-08-11 13:32:16.298421] Получаем результат с нуля...
[2025-08-11 13:32:17.389184] Кешируем полученный результат.
[2025-08-11 13:32:17.389293] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:32:17.389388] * CACHE_HASH_KEY: 75e66cdbe43bbe6fd18c5560f77da3f5c82a3269.
[2025-08-11 13:34:31.733049] Поиск результата в кеше...
[2025-08-11 13:34:31.733275] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:34:31.733339] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:34:31.733392] * CACHE_HASH_KEY: b65fcfe93065d1d357062211efc8bdafbe2fdba9.
[2025-08-11 13:34:31.733664] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. '].
[2025-08-11 13:34:31.733801] Получаем результат с нуля...
[2025-08-11 13:34:32.927979] Кешируем полученный результат.
[2025-08-11 13:34:32.928082] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:34:32.928174] * CACHE_HASH_KEY: b65fcfe93065d1d357062211efc8bdafbe2fdba9.
[2025-08-11 13:35:25.488472] Поиск результата в кеше...
[2025-08-11 13:35:25.488982] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:35:25.489120] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:35:25.489224] * CACHE_HASH_KEY: b57cfe1e649d8668808ee1ebe2de2793779f5142.
[2025-08-11 13:35:25.489868] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. \nba: Какие форматы представления текстовой информации доступны сейчас (например, документы Word, PDF-файлы, веб-страницы, электронные письма)? Будет ли предоставляться доступ ко всем источникам сразу или потребуется организовать процесс сбора и подготовки данных отдельно?\nuser: Скорее всего будет предоставлен исходный набор источников сразу в формате pdf-документов'].
[2025-08-11 13:35:25.490127] Получаем результат с нуля...
[2025-08-11 13:35:26.833413] Кешируем полученный результат.
[2025-08-11 13:35:26.833518] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:35:26.833612] * CACHE_HASH_KEY: b57cfe1e649d8668808ee1ebe2de2793779f5142.
[2025-08-11 13:37:02.694556] Поиск результата в кеше...
[2025-08-11 13:37:02.695025] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:37:02.695157] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:37:02.695330] * CACHE_HASH_KEY: 1adda32c2f91e77e74cefd69dccb5ec4474cbccf.
[2025-08-11 13:37:02.695983] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. \nba: Какие форматы представления текстовой информации доступны сейчас (например, документы Word, PDF-файлы, веб-страницы, электронные письма)? Будет ли предоставляться доступ ко всем источникам сразу или потребуется организовать процесс сбора и подготовки данных отдельно?\nuser: Скорее всего будет предоставлен исходный набор источников сразу в формате pdf-документов\nba: Какие технические характеристики и особенности форматирования PDF-документов следует учитывать при обработке текстов (например, наличие таблиц, изображений, специфического шрифта, структуры разделов)?\nuser: из pdf-документов потребуется извлекать только абзацы текста, минуя таблицы и изображения. При этом должна распознаваться структура документа: разделы/подазделы, абзацы, заголовки'].
[2025-08-11 13:37:02.696247] Получаем результат с нуля...
[2025-08-11 13:37:03.665147] Кешируем полученный результат.
[2025-08-11 13:37:03.665256] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:37:03.665354] * CACHE_HASH_KEY: 1adda32c2f91e77e74cefd69dccb5ec4474cbccf.
[2025-08-11 13:37:51.590555] Поиск результата в кеше...
[2025-08-11 13:37:51.591037] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:37:51.591175] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:37:51.591283] * CACHE_HASH_KEY: 4ef399ffa308071a1ad0e5aacaf33d3fa30ab15d.
[2025-08-11 13:37:51.591957] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. \nba: Какие форматы представления текстовой информации доступны сейчас (например, документы Word, PDF-файлы, веб-страницы, электронные письма)? Будет ли предоставляться доступ ко всем источникам сразу или потребуется организовать процесс сбора и подготовки данных отдельно?\nuser: Скорее всего будет предоставлен исходный набор источников сразу в формате pdf-документов\nba: Какие технические характеристики и особенности форматирования PDF-документов следует учитывать при обработке текстов (например, наличие таблиц, изображений, специфического шрифта, структуры разделов)?\nuser: из pdf-документов потребуется извлекать только абзацы текста, минуя таблицы и изображения. При этом должна распознаваться структура документа: разделы/подазделы, абзацы, заголовки\nba: Какие языки используются в предоставляемых PDF-документах, и требуется ли поддержка мультиязычности в процессе обработки и анализа текстовой информации?\nuser: в PDF-документах будут присутствовать тексты на русском языке. Поддержка мультиязычности в рамках текущего проекта не предполагается'].
[2025-08-11 13:37:51.592228] Получаем результат с нуля...
[2025-08-11 13:37:52.538822] Кешируем полученный результат.
[2025-08-11 13:37:52.538926] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:37:52.539021] * CACHE_HASH_KEY: 4ef399ffa308071a1ad0e5aacaf33d3fa30ab15d.
[2025-08-11 13:38:51.477835] Поиск результата в кеше...
[2025-08-11 13:38:51.478320] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:38:51.478458] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:38:51.478566] * CACHE_HASH_KEY: 5799e5b5f4be500a0b1592455315fd2433bd9525.
[2025-08-11 13:38:51.479456] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. \nba: Какие форматы представления текстовой информации доступны сейчас (например, документы Word, PDF-файлы, веб-страницы, электронные письма)? Будет ли предоставляться доступ ко всем источникам сразу или потребуется организовать процесс сбора и подготовки данных отдельно?\nuser: Скорее всего будет предоставлен исходный набор источников сразу в формате pdf-документов\nba: Какие технические характеристики и особенности форматирования PDF-документов следует учитывать при обработке текстов (например, наличие таблиц, изображений, специфического шрифта, структуры разделов)?\nuser: из pdf-документов потребуется извлекать только абзацы текста, минуя таблицы и изображения. При этом должна распознаваться структура документа: разделы/подазделы, абзацы, заголовки\nba: Какие языки используются в предоставляемых PDF-документах, и требуется ли поддержка мультиязычности в процессе обработки и анализа текстовой информации?\nuser: в PDF-документах будут присутствовать тексты на русском языке. Поддержка мультиязычности в рамках текущего проекта не предполагается\nba: Какие существуют типичные ошибки или проблемы в текущих коммуникациях менеджеров с клиентами, которые цифровой наставник должен выявлять и исправлять в первую очередь?\nuser: Сейчас у нас нет такой информации. В рамках данного проекта это потребуется выяснить в рамках ревью с нашимы специалистами по данному вопросу.'].
[2025-08-11 13:38:51.479755] Получаем результат с нуля...
[2025-08-11 13:38:53.336684] Кешируем полученный результат.
[2025-08-11 13:38:53.336786] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:38:53.336877] * CACHE_HASH_KEY: 5799e5b5f4be500a0b1592455315fd2433bd9525.
[2025-08-11 13:41:02.985362] Поиск результата в кеше...
[2025-08-11 13:41:02.985870] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-11 13:41:02.986004] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:41:02.986307] * CACHE_HASH_KEY: f4ba0de2b2260c830e45bbbe19281e0605fa3a8d.
[2025-08-11 13:41:02.987042] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Целью данного исследования является создание графа знаний, который может быть использован в качестве внешней памяти для таких LLM агентов банка как виртуальный тренажер для клиентских менеджеров, а также агент для обобщения обратной связи от клиентов с целью развития продуктов Банка. Одним из направлений использования такого графа является цифровой наставник, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы данных (памяти) о продукте и даёт рекомендации. Существующие решения, аналогичные цифровому наставнику, такие как 3WIN-AI Training Simulator [1], представляют собой коммерческие, closed-source решения, архитектура которых закрыта.  Цифровой наставник обладает следующим функционалом: 1.\tВалидация ответа менеджера в рамках текущей коммуникации с клиентом. 2.\tКорректировка ответа менеджера в зависимости от сделанных ошибок. 3.\tРекомендация возможного ответа для клиента в рамках текущей коммуникации. 4.\tФормирование пространства памяти наставника за счёт структурированных и слабоструктурированных текстовых данных.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: MVP цифрового наставника, который может: 1. Обновлять и изменять граф знаний с использованием данных из структурированных источников (критерий – построение графа без ошибок со внесением информации). 2. Вносить в граф знаний сущности и связи из слабоструктурированных источников (критерий – построение графа без ошибок со внесением информации). 3. Формировать ответы на основе построенного графа знаний (критерий – метрики полного совпадения (EM), F1-score). 4. Валидировать ответ менеджера на предмет корректности формата коммуникации с клиентом (критерий – F1-score). 5. Верифицировать фактологическую информацию в ответе менеджера на основе построенного графа знаний (критерий – F1-score).\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Менеджеры технической поддержки по общению с клиентами банка\nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: 1. Потребуется подготовить набор текстовых документов, на основе которых цифровой тренажёр должен валидировать ответы клиентского менеджера. 2. Необходимо сформировать методологии, по которым клиентский менеджер ведёт коммуникацию\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии качества ответов агента будут использоваться помимо EM и F1-score, и каким образом они повлияют на оценку эффективности цифрового наставника?\nuser: только EM и F1-score\nba: Какие типы структурированных и слабоструктурированных данных будут использованы для формирования графа знаний, и какой объем этих данных ожидается на начальном этапе разработки MVP?\nuser: Для построения графа знаний будут использоваться только данные в текстовом формате, которые содержат информацию на естественном языке. По количеству ожидается несколько тысяч абзацев текста\nba: Какие категории информации (например, описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы и т.д.) содержатся в указанных текстовых данных, и насколько детализированными они должны быть для эффективного функционирования цифрового наставника?\nuser: Думаем в этих текстах точно будет присутствовать эти категории информации: описание продуктов банка, правила взаимодействия с клиентами, часто задаваемые вопросы. Возможно что-то ешё: в рамках проекта потребуется в отдельности проанализировать имеющиеся наборы информации для её категоризации/систематизации. \nba: Какие форматы представления текстовой информации доступны сейчас (например, документы Word, PDF-файлы, веб-страницы, электронные письма)? Будет ли предоставляться доступ ко всем источникам сразу или потребуется организовать процесс сбора и подготовки данных отдельно?\nuser: Скорее всего будет предоставлен исходный набор источников сразу в формате pdf-документов\nba: Какие технические характеристики и особенности форматирования PDF-документов следует учитывать при обработке текстов (например, наличие таблиц, изображений, специфического шрифта, структуры разделов)?\nuser: из pdf-документов потребуется извлекать только абзацы текста, минуя таблицы и изображения. При этом должна распознаваться структура документа: разделы/подазделы, абзацы, заголовки\nba: Какие языки используются в предоставляемых PDF-документах, и требуется ли поддержка мультиязычности в процессе обработки и анализа текстовой информации?\nuser: в PDF-документах будут присутствовать тексты на русском языке. Поддержка мультиязычности в рамках текущего проекта не предполагается\nba: Какие существуют типичные ошибки или проблемы в текущих коммуникациях менеджеров с клиентами, которые цифровой наставник должен выявлять и исправлять в первую очередь?\nuser: Сейчас у нас нет такой информации. В рамках данного проекта это потребуется выяснить в рамках ревью с нашимы специалистами по данному вопросу.\nba: Какие временные рамки установлены для реализации MVP цифрового наставника, и каковы приоритеты этапов разработки (создание графа знаний, обучение модели, тестирование и внедрение)?\nuser: На разработку MVP выделяется 6 месяцев. Приоритетом является проектирование и разработка графа знаний, который сможет поддерживать оговоренные выше функции'].
[2025-08-11 13:41:02.987324] Получаем результат с нуля...
[2025-08-11 13:41:03.945379] Кешируем полученный результат.
[2025-08-11 13:41:03.945489] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-11 13:41:03.945586] * CACHE_HASH_KEY: f4ba0de2b2260c830e45bbbe19281e0605fa3a8d.
[2025-08-19 14:41:14.476092] Поиск результата в кеше...
[2025-08-19 14:41:14.512732] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:41:14.512820] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:41:14.512873] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 14:41:14.513105] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', ''].
[2025-08-19 14:41:14.513215] Получаем результат с нуля...
[2025-08-19 14:41:15.512521] Кешируем полученный результат.
[2025-08-19 14:41:15.512551] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:41:15.512571] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 14:45:25.226718] Поиск результата в кеше...
[2025-08-19 14:45:25.227156] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:45:25.227288] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:45:25.227393] * CACHE_HASH_KEY: 741706e61fce6194a42461799a9ee4e6dac2265f.
[2025-08-19 14:45:25.227911] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?'].
[2025-08-19 14:45:25.228142] Получаем результат с нуля...
[2025-08-19 14:45:27.369649] Кешируем полученный результат.
[2025-08-19 14:45:27.369757] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:45:27.369850] * CACHE_HASH_KEY: 741706e61fce6194a42461799a9ee4e6dac2265f.
[2025-08-19 14:46:56.633810] Поиск результата в кеше...
[2025-08-19 14:46:56.634231] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:46:56.634360] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:46:56.634462] * CACHE_HASH_KEY: d3d03688e88f2a8b41a1d56320a0458b12ecd98a.
[2025-08-19 14:46:56.634994] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие эталонные ответы или шаблоны правильных формулировок существуют сейчас у вас в банке, которые могли бы служить основой для разработки критериев правильности и корректности ответов менеджеров?\nuser: У нас нет эталонных ответов. Такой датасет потребуется подготовить для оценки качества функциональности, указанной ранее.'].
[2025-08-19 14:46:56.635227] Получаем результат с нуля...
[2025-08-19 14:46:57.646153] Кешируем полученный результат.
[2025-08-19 14:46:57.646252] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:46:57.646341] * CACHE_HASH_KEY: d3d03688e88f2a8b41a1d56320a0458b12ecd98a.
[2025-08-19 14:48:58.252657] Поиск результата в кеше...
[2025-08-19 14:48:58.252775] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:48:58.252805] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:48:58.252827] * CACHE_HASH_KEY: 68c5d6129ade4d162261f857aa8f65fd8bd99590.
[2025-08-19 14:48:58.252976] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие эталонные ответы или шаблоны правильных формулировок существуют сейчас у вас в банке, которые могли бы служить основой для разработки критериев правильности и корректности ответов менеджеров?\nuser: У нас нет эталонных ответов. Такой датасет потребуется подготовить для оценки качества функциональности, указанной ранее.\nba: Какие источники информации будут использованы для формирования эталонных ответов и правил общения с клиентами, которые лягут в основу обучающего датасета и критериев оценки качества работы цифрового наставника?\nuser: Можно брать любые источники. Необходимо, чтобы заявленный функционал системы был переимспольем: возможна итеграция в другие предметные области и для других кейсов.'].
[2025-08-19 14:48:58.253026] Получаем результат с нуля...
[2025-08-19 14:48:59.664465] Кешируем полученный результат.
[2025-08-19 14:48:59.664566] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:48:59.664657] * CACHE_HASH_KEY: 68c5d6129ade4d162261f857aa8f65fd8bd99590.
[2025-08-19 14:50:35.340468] Поиск результата в кеше...
[2025-08-19 14:50:35.340869] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:50:35.340983] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:50:35.341074] * CACHE_HASH_KEY: 9a7dd7f2b2af49ef6dd11a1643ba943833584fd3.
[2025-08-19 14:50:35.341619] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие эталонные ответы или шаблоны правильных формулировок существуют сейчас у вас в банке, которые могли бы служить основой для разработки критериев правильности и корректности ответов менеджеров?\nuser: У нас нет эталонных ответов. Такой датасет потребуется подготовить для оценки качества функциональности, указанной ранее.\nba: Какие источники информации будут использованы для формирования эталонных ответов и правил общения с клиентами, которые лягут в основу обучающего датасета и критериев оценки качества работы цифрового наставника?\nuser: Можно брать любые источники. Необходимо, чтобы заявленный функционал системы был переимспольем: возможна итеграция в другие предметные области и для других кейсов.\nba: Какие конкретные шаги и методы планируете использовать для сбора и подготовки данных, необходимых для формирования эталонных ответов и правил общения с клиентами, учитывая отсутствие готовых источников этой информации в вашем банке?\nuser: Потребуется отобрать базовые QA-датасеты. Далее на их основе синтезировать вопросно-ответные пары для оценки качества функционала по валидации, генерации, коррекции ответов клиентских  менеджеров'].
[2025-08-19 14:50:35.341848] Получаем результат с нуля...
[2025-08-19 14:50:36.643148] Кешируем полученный результат.
[2025-08-19 14:50:36.643245] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:50:36.643333] * CACHE_HASH_KEY: 9a7dd7f2b2af49ef6dd11a1643ba943833584fd3.
[2025-08-19 14:51:37.428626] Поиск результата в кеше...
[2025-08-19 14:51:37.429071] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:51:37.429200] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:51:37.429305] * CACHE_HASH_KEY: 6a6213489b39beaedfbc0d03d43b1827c77b8e97.
[2025-08-19 14:51:37.429939] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие эталонные ответы или шаблоны правильных формулировок существуют сейчас у вас в банке, которые могли бы служить основой для разработки критериев правильности и корректности ответов менеджеров?\nuser: У нас нет эталонных ответов. Такой датасет потребуется подготовить для оценки качества функциональности, указанной ранее.\nba: Какие источники информации будут использованы для формирования эталонных ответов и правил общения с клиентами, которые лягут в основу обучающего датасета и критериев оценки качества работы цифрового наставника?\nuser: Можно брать любые источники. Необходимо, чтобы заявленный функционал системы был переимспольем: возможна итеграция в другие предметные области и для других кейсов.\nba: Какие конкретные шаги и методы планируете использовать для сбора и подготовки данных, необходимых для формирования эталонных ответов и правил общения с клиентами, учитывая отсутствие готовых источников этой информации в вашем банке?\nuser: Потребуется отобрать базовые QA-датасеты. Далее на их основе синтезировать вопросно-ответные пары для оценки качества функционала по валидации, генерации, коррекции ответов клиентских  менеджеров\nba: Какие именно QA-датасеты планируется использовать в качестве основы для синтеза вопросно-ответных пар, и каким образом будет обеспечиваться соответствие этих наборов данных специфике продуктов и услуг вашего банка?\nuser: Мы пока не знаем какие датаскты будут использованы. Для оценки качества нам не важна специфика датасета'].
[2025-08-19 14:51:37.430184] Получаем результат с нуля...
[2025-08-19 14:51:38.471507] Кешируем полученный результат.
[2025-08-19 14:51:38.471602] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:51:38.471690] * CACHE_HASH_KEY: 6a6213489b39beaedfbc0d03d43b1827c77b8e97.
[2025-08-19 14:52:13.953286] Поиск результата в кеше...
[2025-08-19 14:52:13.953765] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 14:52:13.953896] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:52:13.954001] * CACHE_HASH_KEY: 62a25a597df76c611399b63926d593f769a758d7.
[2025-08-19 14:52:13.954628] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильности" или "корректности" ответов менеджеров, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие эталонные ответы или шаблоны правильных формулировок существуют сейчас у вас в банке, которые могли бы служить основой для разработки критериев правильности и корректности ответов менеджеров?\nuser: У нас нет эталонных ответов. Такой датасет потребуется подготовить для оценки качества функциональности, указанной ранее.\nba: Какие источники информации будут использованы для формирования эталонных ответов и правил общения с клиентами, которые лягут в основу обучающего датасета и критериев оценки качества работы цифрового наставника?\nuser: Можно брать любые источники. Необходимо, чтобы заявленный функционал системы был переимспольем: возможна итеграция в другие предметные области и для других кейсов.\nba: Какие конкретные шаги и методы планируете использовать для сбора и подготовки данных, необходимых для формирования эталонных ответов и правил общения с клиентами, учитывая отсутствие готовых источников этой информации в вашем банке?\nuser: Потребуется отобрать базовые QA-датасеты. Далее на их основе синтезировать вопросно-ответные пары для оценки качества функционала по валидации, генерации, коррекции ответов клиентских  менеджеров\nba: Какие именно QA-датасеты планируется использовать в качестве основы для синтеза вопросно-ответных пар, и каким образом будет обеспечиваться соответствие этих наборов данных специфике продуктов и услуг вашего банка?\nuser: Мы пока не знаем какие датаскты будут использованы. Для оценки качества нам не важна специфика датасета\nba: Какие подходы и инструменты планируется применять для обеспечения репрезентативности и разнообразия синтетически созданных вопросно-ответных пар, чтобы они максимально полно отражали реальные сценарии взаимодействия менеджеров с клиентами?\nuser: Мы пока не знаем. Какие варианты можете предложить?'].
[2025-08-19 14:52:13.954874] Получаем результат с нуля...
[2025-08-19 14:52:15.336640] Кешируем полученный результат.
[2025-08-19 14:52:15.336740] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 14:52:15.336833] * CACHE_HASH_KEY: 62a25a597df76c611399b63926d593f769a758d7.
[2025-08-19 16:11:59.312597] Поиск результата в кеше...
[2025-08-19 16:11:59.313052] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:11:59.313196] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:11:59.313305] * CACHE_HASH_KEY: 1884e205c5a3c7f29b7b61ee639a07152a24e1d0.
[2025-08-19 16:11:59.313822] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', ''].
[2025-08-19 16:11:59.314068] Получаем результат с нуля...
[2025-08-19 16:12:00.226383] Кешируем полученный результат.
[2025-08-19 16:12:00.226488] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:12:00.226580] * CACHE_HASH_KEY: 1884e205c5a3c7f29b7b61ee639a07152a24e1d0.
[2025-08-19 16:12:20.713057] Поиск результата в кеше...
[2025-08-19 16:12:20.713379] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:12:20.713496] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:12:20.713575] * CACHE_HASH_KEY: c7c3498a5069bf1d8b31ce83db30fa36271c5f42.
[2025-08-19 16:12:20.713924] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии оценки эффективности разработанной библиотеки будут использоваться для подтверждения достижения уровня мировой SOTA на бенчмарке LOCOMO?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?'].
[2025-08-19 16:12:20.714084] Получаем результат с нуля...
[2025-08-19 16:12:22.178096] Кешируем полученный результат.
[2025-08-19 16:12:22.178152] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:12:22.178202] * CACHE_HASH_KEY: c7c3498a5069bf1d8b31ce83db30fa36271c5f42.
[2025-08-19 16:13:08.756532] Поиск результата в кеше...
[2025-08-19 16:13:08.756957] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:13:08.757087] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:13:08.757189] * CACHE_HASH_KEY: 5688752fc4b3e4dca9946d2858153f45406459b1.
[2025-08-19 16:13:08.757738] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии оценки эффективности разработанной библиотеки будут использоваться для подтверждения достижения уровня мировой SOTA на бенчмарке LOCOMO?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие целевые значения каждой из указанных вами метрик (Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE) следует достичь, чтобы считать результаты удовлетворительными и соответствующими уровню мировой SOTA на бенчмарке LOCOMO?\nuser: Выше среднего. Конкретных значений не можем предоставить'].
[2025-08-19 16:13:08.757972] Получаем результат с нуля...
[2025-08-19 16:13:09.779175] Кешируем полученный результат.
[2025-08-19 16:13:09.779272] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:13:09.779357] * CACHE_HASH_KEY: 5688752fc4b3e4dca9946d2858153f45406459b1.
[2025-08-19 16:13:32.799879] Поиск результата в кеше...
[2025-08-19 16:13:32.800121] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:13:32.800207] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:13:32.800263] * CACHE_HASH_KEY: c8bf0db9426405e00d9e6c9402206d084da4b15e.
[2025-08-19 16:13:32.800547] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии оценки эффективности разработанной библиотеки будут использоваться для подтверждения достижения уровня мировой SOTA на бенчмарке LOCOMO?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие целевые значения каждой из указанных вами метрик (Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE) следует достичь, чтобы считать результаты удовлетворительными и соответствующими уровню мировой SOTA на бенчмарке LOCOMO?\nuser: Выше среднего. Конкретных значений не можем предоставить\nba: Какие конкретные шаги и методики планируете использовать для подготовки датасетов, необходимых для оценки качества функций валидации, генерации рекомендаций и корректировки ответов менеджеров?\nuser: Потребуется отобрать базовые QA-датасеты. Далее на их основе синтезировать вопросно-ответные пары для оценки качества функционала по валидации, генерации, коррекции ответов клиентских  менеджеров'].
[2025-08-19 16:13:32.800667] Получаем результат с нуля...
[2025-08-19 16:13:34.004338] Кешируем полученный результат.
[2025-08-19 16:13:34.004436] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:13:34.004526] * CACHE_HASH_KEY: c8bf0db9426405e00d9e6c9402206d084da4b15e.
[2025-08-19 16:14:58.882364] Поиск результата в кеше...
[2025-08-19 16:14:58.882808] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:14:58.882934] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:14:58.883034] * CACHE_HASH_KEY: bbe2709162588848116af8e73a4cff6bdde80c02.
[2025-08-19 16:14:58.883614] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необходимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии оценки эффективности разработанной библиотеки будут использоваться для подтверждения достижения уровня мировой SOTA на бенчмарке LOCOMO?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие целевые значения каждой из указанных вами метрик (Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE) следует достичь, чтобы считать результаты удовлетворительными и соответствующими уровню мировой SOTA на бенчмарке LOCOMO?\nuser: Выше среднего. Конкретных значений не можем предоставить\nba: Какие конкретные шаги и методики планируете использовать для подготовки датасетов, необходимых для оценки качества функций валидации, генерации рекомендаций и корректировки ответов менеджеров?\nuser: Потребуется отобрать базовые QA-датасеты. Далее на их основе синтезировать вопросно-ответные пары для оценки качества функционала по валидации, генерации, коррекции ответов клиентских  менеджеров\nba: Какие источники данных будут использованы для отбора базовых QA-датасетов, и каким образом будет обеспечиваться репрезентативность этих наборов данных относительно реальных сценариев взаимодействия клиентских менеджеров с клиентами Банка?\nuser: Можно брать любые источники. Необходимо, чтобы заявленный функционал системы был переимспольем: возможна итеграция в другие предметные области и для других кейсов.'].
[2025-08-19 16:14:58.883859] Получаем результат с нуля...
[2025-08-19 16:14:59.968733] Кешируем полученный результат.
[2025-08-19 16:14:59.968827] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:14:59.968915] * CACHE_HASH_KEY: bbe2709162588848116af8e73a4cff6bdde80c02.
[2025-08-19 16:21:43.494070] Поиск результата в кеше...
[2025-08-19 16:21:43.494189] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:21:43.494219] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:21:43.494243] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 16:21:43.494353] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', ''].
[2025-08-19 16:21:43.494405] Получаем результат с нуля...
[2025-08-19 16:21:44.410540] Кешируем полученный результат.
[2025-08-19 16:21:44.410646] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:21:44.410737] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 16:22:08.013879] Поиск результата в кеше...
[2025-08-19 16:22:08.014128] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:22:08.014202] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:22:08.014268] * CACHE_HASH_KEY: a5dfb4c76efa0f96dcc40ca5edae42bbd30e2ae2.
[2025-08-19 16:22:08.014475] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера клиенту, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?'].
[2025-08-19 16:22:08.014569] Получаем результат с нуля...
[2025-08-19 16:22:09.225420] Кешируем полученный результат.
[2025-08-19 16:22:09.225532] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:22:09.225624] * CACHE_HASH_KEY: a5dfb4c76efa0f96dcc40ca5edae42bbd30e2ae2.
[2025-08-19 16:23:06.952108] Поиск результата в кеше...
[2025-08-19 16:23:06.952545] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:23:06.952676] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:23:06.952775] * CACHE_HASH_KEY: b6edce347da524b3fff5461a749b0e55e03c7da9.
[2025-08-19 16:23:06.953341] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера клиенту, и кто будет ответственен за разработку этих критериев?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие конкретные сценарии взаимодействия клиентских менеджеров с цифровым наставником следует учитывать при разработке функционала библиотеки? Например, типичные ситуации, когда требуется проверка ответа менеджера, получение рекомендаций или коррекция ответа.\nuser: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента'].
[2025-08-19 16:23:06.953651] Получаем результат с нуля...
[2025-08-19 16:23:07.887572] Кешируем полученный результат.
[2025-08-19 16:23:07.887671] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:23:07.887764] * CACHE_HASH_KEY: b6edce347da524b3fff5461a749b0e55e03c7da9.
[2025-08-19 16:31:08.234732] Поиск результата в кеше...
[2025-08-19 16:31:08.235174] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:31:08.235497] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:31:08.235639] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 16:31:08.236141] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', ''].
[2025-08-19 16:31:08.236370] Получаем результат с нуля...
[2025-08-19 16:31:09.248521] Кешируем полученный результат.
[2025-08-19 16:31:09.248623] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:31:09.248711] * CACHE_HASH_KEY: 05c257ce37b1b5df1b2df9ea62a55d9a94cb5aaf.
[2025-08-19 16:31:30.636609] Поиск результата в кеше...
[2025-08-19 16:31:30.637048] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:31:30.637179] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:31:30.637283] * CACHE_HASH_KEY: 8aa5ffceafbc02ca3025ae902fec750ecfad7a59.
[2025-08-19 16:31:30.637833] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера при валидации и корректировке ответов в рамках текущего диалога с клиентом?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?'].
[2025-08-19 16:31:30.638073] Получаем результат с нуля...
[2025-08-19 16:31:32.304140] Кешируем полученный результат.
[2025-08-19 16:31:32.304250] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:31:32.304345] * CACHE_HASH_KEY: 8aa5ffceafbc02ca3025ae902fec750ecfad7a59.
[2025-08-19 16:32:10.131885] Поиск результата в кеше...
[2025-08-19 16:32:10.132326] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:32:10.132454] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:32:10.132559] * CACHE_HASH_KEY: 0d95bf7ee0a9ae5f9e57a074f52d118ecb81920d.
[2025-08-19 16:32:10.133129] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера при валидации и корректировке ответов в рамках текущего диалога с клиентом?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие конкретные сценарии взаимодействия клиентского менеджера с цифровым наставником следует учитывать при разработке функционала валидации, корректировки и рекомендации ответов? Например, типичные ситуации возникновения возражений у клиентов, сложные запросы или нестандартные случаи обслуживания.\nuser: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента'].
[2025-08-19 16:32:10.133445] Получаем результат с нуля...
[2025-08-19 16:32:11.168592] Кешируем полученный результат.
[2025-08-19 16:32:11.168695] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:32:11.168786] * CACHE_HASH_KEY: 0d95bf7ee0a9ae5f9e57a074f52d118ecb81920d.
[2025-08-19 16:32:26.055869] Поиск результата в кеше...
[2025-08-19 16:32:26.056114] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:32:26.056180] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:32:26.056234] * CACHE_HASH_KEY: e85cbea06eeadbfcf4d53b9ac226a005915ebd23.
[2025-08-19 16:32:26.056526] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера при валидации и корректировке ответов в рамках текущего диалога с клиентом?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие конкретные сценарии взаимодействия клиентского менеджера с цифровым наставником следует учитывать при разработке функционала валидации, корректировки и рекомендации ответов? Например, типичные ситуации возникновения возражений у клиентов, сложные запросы или нестандартные случаи обслуживания.\nuser: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Какие типы ошибок чаще всего допускают клиентские менеджеры при общении с клиентами, и как эти ошибки влияют на удовлетворенность клиентов и результаты бизнеса?\nuser: У нас нет такой информации'].
[2025-08-19 16:32:26.056656] Получаем результат с нуля...
[2025-08-19 16:32:26.904297] Кешируем полученный результат.
[2025-08-19 16:32:26.904403] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:32:26.904493] * CACHE_HASH_KEY: e85cbea06eeadbfcf4d53b9ac226a005915ebd23.
[2025-08-19 16:33:11.955722] Поиск результата в кеше...
[2025-08-19 16:33:11.956172] Результата по заданной конфигурации гиперпараметров в кеше нет.
[2025-08-19 16:33:11.956297] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:33:11.956398] * CACHE_HASH_KEY: 7b751c0096a7b11acce6a467dee8a0e8a4ec5ce8.
[2025-08-19 16:33:11.956990] * HASH_SEEDS: ['gigachat|temperature=0;top_k=1;top_p=0|model=GigaChat-Max;scope=GIGACHAT_API_PERS;token=ZmUzMGYxMzUtZmEwMi00ODZkLTlmNmUtY2NkYjk2ZmQ1ZTQyOjhmMmI2ZGZjLWI5MzMtNDI0Ny1iNmFkLTQ4NGY5NDNkMmJmOQ==|v1|ru', 'ba: Опишите вашу задачу простыми словами.\nuser: Необъодимо разработать цифрового наставника, который анализирует коммуникации менеджера с клиентами Банка, проверяет информацию на основе своей базы знаний (памяти) о продукте и даёт рекомендации. Наставник должен поддерживать обновление и изменение графа знаний, а также обеспечивать валидацию и верификацию ответов менеджеров согласно установленным правилам и критериям оценки.\nba: Какую проблему вы хотите решить с помощью продукта?\nuser: В Банке разрабатываются системы анализа коммуникаций с клиентами. Среди таких систем создаются цифровые тренажеры для клиентских менеджеров, которые позволяют, отрабатывать навыки работы с клиентами, в том числе работу с возражениями, повышать квалификацию клиентских менеджеров, и в конечном итоге повышать конверсию продаж. Кроме того, системы анализа коммуникаций с клиентами позволяют развивать продукты Банка через обратную связь, включая вопросы, жалобы и предложения, таким образом обобщая клиентский опыт.  Для работы со слабоструктурированной информацией, содержащейся в коммуникациях, необходимы LLM агенты, которые должны понимать семантику сообщений и диалогов. Для того, чтобы такой агент мог накапливать знания, его нужно снабдить внешней памятью. Исследования, в том числе проведенные Сколтехом, показывают, что наиболее эффективным инструментом создания внешней памяти для LLM-агентов являются графы знаний.  Создание такого цифрового тренажера, использующего граф как внешнюю память LLM-агента, позволит значительно повысить качество работы менеджеров с клиентами, снизить отток и повысить лояльность клиентов, и таким образом позволит повысить прибыль Банка.\nba: Какой результат вы ожидаете? (Что должно быть на выходе?)\nuser: Программную библиотеку с следующим фцнкионалом: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Кто будет пользоваться продуктом? (Целевая аудитория)\nuser: Продуктом будут пользоваться клиентские менеджеры для проверки/валидации своих ответов и получения базовых вариантов ответа для клиентов на их вопросы \nba: Есть ли предпочтения по технологиям или ограничения?\nuser: Одним из наиболее перспективных SOTA подходов является идея создания полноценной памяти агентов, построенных на основе графов. В общих фреймворках для построения и отслеживания LLM агентов, таких как LangGraph [5], есть некоторая фунциональность для работы с памятью агентов. Однако мы будем опираться на более специализированные решения.  В текущем году было представлено несколько решений по построению внешней памяти агентов на графах, среди них можно выделить две работы: Mem0 ("mem-zero") [6] и A-Mem: Agentic Memory [7]. В качестве бенчмарка для тестирования перечисленных решений использовался датасет LOCOMO [8], содержащий диалоги и вопросы к ним. Средняя длина диалога составляет 26000 токенов, и несмотря на то, что в настоящее время LLMs имеют возможность обработки такой длины контекста, было показано, что эффективность использования информации из контекста при генерации падает при увеличении длины контекста [9]. Таким образом, бенчмарк LOCOMO дает возможность оценить эффективность сохранения и извлечения фактов из внешней памяти для использования LLM агентом при генерации сообщений в диалоге. Граф знаний в решении AriGraph [2, 3], на котором будет базироваться данная работа, сочетает в себе как структурированные элементы (узлы и связи в семантической памяти, связи между семантическими и эпизодическими узлами), так и неструктурированные (текст в эпизодических узлах), что представляет собой потенциальное преимущество перед вышеперечисленными подходами. В работе [2] были приведены SOTA метрики (Exact Match) подхода AriGraph на датасете HotpotQA. В ходе данного проекта предполагается улучшение алгоритма извлечения и фильтрации релевантных фактов из графа знаний в системе AriGraph. Подтверждение данных предположений на бенчмарке LOCOMO будет представлять решение на уровне мировой SOTA, и будет означать существенное развитие технологий построения LLM-агентов.\nba: Какие данные уже есть, и какие данные нужно собирать?\nuser: Никаких данных нет, но потебуется подготовить датасеты для оценки качества следующих функций: (1) валидация ответов клиентских менеджеров; (2) генерация рекомендаций / вариантов ответа на вопросы клиентов; (3) корректировка ответов менеджеров на вопросы клиентов\nba: Есть ли интеграции с другими системами?\nuser: Интеграции с другими системами нет\nba: Какие есть дополнительные пожелания или требования?\nuser: Поскольку для надежной архитектуры памяти необходима интеграция как структурированных, так и неструктурированных данных, такая интеграция осуществляется параллельно с концепциями семантической и эпизодической памяти. Граф знаний представляет собой сеть взаимосвязанных семантических знаний, в то время как эпизодические воспоминания отображаются в виде эпизодических ребер, которые могут связывать множество отношений внутри графа.  Построение графа, а также валидация и корректировка ответа менеджера будут реализованы в виде агентов на основе LLM. Тестирование алгоритмов планируется проводить с использованием GigaChat (при наличии доступа к вычислительным и информационным ресурсам Сбербанка), либо с LLaMA и QWEN (на мощностях Сколтеха). Финальное решение будет реализовано с использованием GigaChat. Предлагаемый подход является развитием подхода AriGraph [2, 3], и будет осуществляться исследовательской командой, в состав которой будут входить авторы данной статьи из Сколтеха.', 'ba: Какие критерии будут использоваться для определения "правильного" ответа менеджера при валидации и корректировке ответов в рамках текущего диалога с клиентом?\nuser: Мы знаем следующие метрики эффективности, за счёт которых можно выполнить оценку заявленных функций:  Faithfulness, Correctness, Relevancy, BLEU, METEOR, ROUGE. Какие метрики нам ещё стоит включить для оценки качества валидации, генерации и коррекции ответов клиентского менеджера?\nba: Какие конкретные сценарии взаимодействия клиентского менеджера с цифровым наставником следует учитывать при разработке функционала валидации, корректировки и рекомендации ответов? Например, типичные ситуации возникновения возражений у клиентов, сложные запросы или нестандартные случаи обслуживания.\nuser: (1) валидация ответа менеджера в рамках текущей коммуникации с клиентом; (2) корректировка ответа менеджера в зависимости от сделанных ошибок; (3) рекомендация возможного ответа менеджера для клиента в рамках текущей коммуникации; (4) формирование пространства памяти цифрового наставника на основе графов знаний, которая будет хранить текущую историю диалога менеджера с клиентом, правила/манифест общения с клиентом и техническую/сопроводительную информацию об услугах банка, на которую должен обуславливаться менеджер (и цифровой наставник) при генерации ответов на вопросы клиента\nba: Какие типы ошибок чаще всего допускают клиентские менеджеры при общении с клиентами, и как эти ошибки влияют на удовлетворенность клиентов и результаты бизнеса?\nuser: У нас нет такой информации\nba: Какие источники информации доступны для сбора данных о типичных ошибках клиентских менеджеров при взаимодействии с клиентами, если внутренняя статистика отсутствует?\nuser: сбор информации об ошибках не требуется'].
[2025-08-19 16:33:11.957236] Получаем результат с нуля...
[2025-08-19 16:33:13.014732] Кешируем полученный результат.
[2025-08-19 16:33:13.014828] * CACHE_TABLE_NAME bpcq_gen_cache
[2025-08-19 16:33:13.014916] * CACHE_HASH_KEY: 7b751c0096a7b11acce6a467dee8a0e8a4ec5ce8.
